{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryanshgitmenongit/PyTorch-Based-implementation-of-Light-GCN-paper/blob/main/final_reco_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8abbed94"
      },
      "source": [
        "# Imports"
      ],
      "id": "8abbed94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06db3c8e",
        "outputId": "3077b030-be86-41d7-e2f9-580ba9e6158e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt21cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "# import required modules\n",
        "# import required modules\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, metrics, preprocessing\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj\n",
        "import torch.nn.functional as F"
      ],
      "id": "06db3c8e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c42e300"
      },
      "source": [
        "# Load Dataset"
      ],
      "id": "9c42e300"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53a38ace"
      },
      "outputs": [],
      "source": [
        "# download the dataset\n",
        "# https://grouplens.org/datasets/movielens/\n",
        "# \"Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018\"\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'\n",
        "user_path = './ml-latest-small/users.csv'"
      ],
      "id": "53a38ace"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcc01c7c"
      },
      "outputs": [],
      "source": [
        "rating_df = pd.read_csv(rating_path)\n",
        "movie_df = pd.read_csv(movie_path)\n",
        "\n",
        "lbl_user = preprocessing.LabelEncoder()\n",
        "lbl_movie = preprocessing.LabelEncoder()\n",
        "\n",
        "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
        "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"
      ],
      "id": "dcc01c7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "335a8286"
      },
      "outputs": [],
      "source": [
        "print(rating_df.userId.max())\n",
        "print(rating_df.movieId.max())"
      ],
      "id": "335a8286"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07f9b0ee"
      },
      "outputs": [],
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(df,\n",
        "                  src_index_col,\n",
        "                  dst_index_col,\n",
        "                  link_index_col,\n",
        "                  rating_threshold=3.5):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        src_index_col (str): column name of users\n",
        "        src_mapping (dict): mapping between row number and user id\n",
        "        dst_index_col (str): column name of items\n",
        "        dst_mapping (dict): mapping between row number and item id\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
        "    \"\"\"\n",
        "\n",
        "    edge_index = None\n",
        "    src = [user_id for user_id in  df['userId']]\n",
        "\n",
        "    num_users = len(df['userId'].unique())\n",
        "\n",
        "    dst = [(movie_id) for movie_id in df['movieId']]\n",
        "\n",
        "    link_vals = df[link_index_col].values\n",
        "\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "    edge_values = []\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "            edge_values.append(link_vals[i])\n",
        "\n",
        "    # edge_values is the label we will use for compute training loss\n",
        "    return edge_index, edge_values"
      ],
      "id": "07f9b0ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "938a5feb"
      },
      "outputs": [],
      "source": [
        "\n",
        "edge_index, edge_values = load_edge_csv(\n",
        "    rating_df,\n",
        "    src_index_col='userId',\n",
        "    dst_index_col='movieId',\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=1 # need to use threshold=1 so the model can learn based on RMSE\n",
        ")"
      ],
      "id": "938a5feb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98409e8c"
      },
      "outputs": [],
      "source": [
        "# Convert to tensor\n",
        "# We use LongTensor here because the .propagate() method in the model needs either LongTensor or SparseTensor\n",
        "edge_index = torch.LongTensor(edge_index)\n",
        "edge_values = torch.tensor(edge_values)\n",
        "\n",
        "print(edge_index)\n",
        "print(edge_index.size())\n",
        "\n",
        "print(edge_values)\n",
        "print(edge_values.size())"
      ],
      "id": "98409e8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd2b5afa"
      },
      "outputs": [],
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "# num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
        "\n",
        "num_users = len(rating_df['userId'].unique())\n",
        "num_movies = len(rating_df['movieId'].unique())\n",
        "\n",
        "print(f\"num_users {num_users}, num_movies {num_movies}\")"
      ],
      "id": "cd2b5afa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5573dbc4"
      },
      "outputs": [],
      "source": [
        "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index, input_edge_values):\n",
        "    R = torch.zeros((num_users, num_movies))\n",
        "    for i in range(len(input_edge_index[0])):\n",
        "        row_idx = input_edge_index[0][i]\n",
        "        col_idx = input_edge_index[1][i]\n",
        "        R[row_idx][col_idx] = input_edge_values[i] # assign actual edge value to Interaction Matrix\n",
        "\n",
        "    R_transpose = torch.transpose(R, 0, 1)\n",
        "\n",
        "    # create adj_matrix\n",
        "    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n",
        "    adj_mat[: num_users, num_users :] = R.clone()\n",
        "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
        "\n",
        "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
        "    adj_mat_coo_indices = adj_mat_coo.indices()\n",
        "    adj_mat_coo_values = adj_mat_coo.values()\n",
        "    return adj_mat_coo_indices, adj_mat_coo_values"
      ],
      "id": "5573dbc4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "788a1df1"
      },
      "outputs": [],
      "source": [
        "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index, input_edge_values):\n",
        "\n",
        "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0],\n",
        "                                           col=input_edge_index[1],\n",
        "                                           value = input_edge_values,\n",
        "                                           sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
        "\n",
        "    adj_mat = sparse_input_edge_index.to_dense()\n",
        "    interact_mat = adj_mat[: num_users, num_users :]\n",
        "\n",
        "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
        "    r_mat_edge_values = interact_mat.to_sparse_coo().values()\n",
        "\n",
        "    return r_mat_edge_index, r_mat_edge_values"
      ],
      "id": "788a1df1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c59e3f35"
      },
      "outputs": [],
      "source": [
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(all_indices,\n",
        "                                               test_size=0.2,\n",
        "                                               random_state=1)\n",
        "\n",
        "val_indices, test_indices = train_test_split(test_indices,\n",
        "                                             test_size=0.5,\n",
        "                                             random_state=1)"
      ],
      "id": "c59e3f35"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee13fb68"
      },
      "outputs": [],
      "source": [
        "train_edge_index = edge_index[:,train_indices]\n",
        "train_edge_value = edge_values[train_indices]\n",
        "\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "val_edge_value = edge_values[val_indices]\n",
        "\n",
        "test_edge_index = edge_index[:, test_indices]\n",
        "test_edge_value = edge_values[test_indices]"
      ],
      "id": "ee13fb68"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae8d9dd1"
      },
      "outputs": [],
      "source": [
        "print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n",
        "print(f\"train_edge_index {train_edge_index}\")\n",
        "print((num_users + num_movies))\n",
        "print(torch.unique(train_edge_index[0]).size())\n",
        "print(torch.unique(train_edge_index[1]).size())\n",
        "\n",
        "print(test_edge_value)\n",
        "print(test_edge_value.size())"
      ],
      "id": "ae8d9dd1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "853bf141"
      },
      "outputs": [],
      "source": [
        "train_edge_index, train_edge_values  = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index, train_edge_value)\n",
        "val_edge_index, val_edge_values = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index, val_edge_value)\n",
        "test_edge_index, test_edge_values = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index, test_edge_value)"
      ],
      "id": "853bf141"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4e13290"
      },
      "outputs": [],
      "source": [
        "print(train_edge_index)\n",
        "print(train_edge_index.size())\n",
        "print(val_edge_index)\n",
        "print(val_edge_index.size())\n",
        "print(test_edge_index)\n",
        "print(test_edge_index.size())\n",
        "\n",
        "print(f\"\\n train_edge_values: \\n {train_edge_values} \\n {train_edge_values.size()}\")\n",
        "print(f\"\\n val_edge_values: \\n {val_edge_values} \\n {val_edge_values.size()}\")\n",
        "print(f\"\\n test_edge_values: \\n {test_edge_values} \\n {test_edge_values.size()}\")"
      ],
      "id": "a4e13290"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaab5b0e"
      },
      "source": [
        "# Implementing LightGCN\n",
        "\n",
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales.\n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix"
      ],
      "id": "eaab5b0e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e8bdc1b"
      },
      "outputs": [],
      "source": [],
      "id": "6e8bdc1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e07d93a"
      },
      "outputs": [],
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False, dropout_rate=0.1):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.K = K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "\n",
        "        # define user and item embedding for direct look up.\n",
        "        # embedding dimension: num_user/num_item x embedding_dim\n",
        "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "\n",
        "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "\n",
        "        # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
        "        # according to LightGCN paper, this gives better performance\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "        # create a linear layer (fully connected layer) so we can output a single value (predicted_rating)\n",
        "        self.out = nn.Linear(embedding_dim + embedding_dim, 1)\n",
        "\n",
        "    def forward(self, edge_index: Tensor, edge_values: Tensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "            compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "            \\tilde_A = D^(-1/2) * A * D^(-1/2)    according to LightGCN paper\n",
        "\n",
        "            this is essentially a metrix operation way to get 1/ (sqrt(n_neighbors_i) * sqrt(n_neighbors_j))\n",
        "\n",
        "\n",
        "            if your original edge_index look like\n",
        "            tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
        "                    [   0,    2,    5,  ..., 9444, 9445, 9485]])\n",
        "\n",
        "                    torch.Size([2, 99466])\n",
        "\n",
        "            then this will output:\n",
        "                (\n",
        "                 tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
        "                         [   0,    2,    5,  ..., 9444, 9445, 9485]]),\n",
        "                 tensor([0.0047, 0.0096, 0.0068,  ..., 0.0592, 0.0459, 0.1325])\n",
        "                 )\n",
        "\n",
        "              where edge_index_norm[0] is just the original edge_index\n",
        "\n",
        "              and edge_index_norm[1] is the symmetrically normalization term.\n",
        "\n",
        "            under the hood it's basically doing\n",
        "                def compute_gcn_norm(edge_index, emb):\n",
        "                    emb = emb.weight\n",
        "                    from_, to_ = edge_index\n",
        "                    deg = degree(to_, emb.size(0), dtype=emb.dtype)\n",
        "                    deg_inv_sqrt = deg.pow(-0.5)\n",
        "                    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "                    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
        "\n",
        "                    return norm\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        edge_index_norm = gcn_norm(edge_index=edge_index,\n",
        "                                   add_self_loops=self.add_self_loops)\n",
        "\n",
        "        # concat the user_emb and item_emb as the layer0 embing matrix\n",
        "        # size will be (n_users + n_items) x emb_vector_len.   e.g: 10334 x 64\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "\n",
        "        embs = [emb_0] # save the layer0 emb to the embs list\n",
        "\n",
        "        # emb_k is the emb that we are actually going to push it through the graph layers\n",
        "        # as described in lightGCN paper formula 7\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # push the embedding of all users and items through the Graph Model K times.\n",
        "        # K here is the number of layers\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
        "            embs.append(emb_k)\n",
        "\n",
        "\n",
        "        # this is doing the formula8 in LightGCN paper\n",
        "\n",
        "        # the stacked embs is a list of embedding matrix at each layer\n",
        "        #    it's of shape n_nodes x (n_layers + 1) x emb_vector_len.\n",
        "        #        e.g: torch.Size([10334, 4, 64])\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "\n",
        "        # From LightGCn paper: \"In our experiments, we find that setting α_k uniformly as 1/(K + 1)\n",
        "        #    leads to good performance in general.\"\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(emb_final,\n",
        "                                                       [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "\n",
        "        r_mat_edge_index, _ = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index, edge_values)\n",
        "\n",
        "        src, dest =  r_mat_edge_index[0], r_mat_edge_index[1]\n",
        "\n",
        "        # applying embedding lookup to get embeddings for src nodes and dest nodes in the edge list\n",
        "        user_embeds = users_emb_final[src]\n",
        "        item_embeds = items_emb_final[dest]\n",
        "\n",
        "        # output dim: edge_index_len x 128 (given 64 is the original emb_vector_len)\n",
        "        output = torch.cat([user_embeds, item_embeds], dim=1)\n",
        "\n",
        "        # push it through the linear layer\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "layers = 1\n",
        "model = LightGCN(num_users=num_users,\n",
        "                 num_items=num_movies,\n",
        "                 K=layers)"
      ],
      "id": "9e07d93a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS8KyAh70sr8"
      },
      "outputs": [],
      "source": [],
      "id": "lS8KyAh70sr8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f5989fc"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n"
      ],
      "id": "0f5989fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c8a59f8"
      },
      "outputs": [],
      "source": [
        "# define constants\n",
        "ITERATIONS = 10000\n",
        "EPOCHS = 10\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 10\n",
        "LAMBDA = 1e-6\n"
      ],
      "id": "4c8a59f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1ITH4xgCnfM"
      },
      "outputs": [],
      "source": [
        "def get_recall_at_k(input_edge_index,\n",
        "                     input_edge_values, # the true label of actual ratings for each user/item interaction\n",
        "                     pred_ratings, # the list of predicted ratings\n",
        "                     k=10,\n",
        "                     threshold=3.5):\n",
        "    with torch.no_grad():\n",
        "        user_item_rating_list = defaultdict(list)\n",
        "\n",
        "        for i in range(len(input_edge_index[0])):\n",
        "            src = input_edge_index[0][i].item()\n",
        "            dest = input_edge_index[1][i].item()\n",
        "            true_rating = input_edge_values[i].item()\n",
        "            pred_rating = pred_ratings[i].item()\n",
        "\n",
        "            user_item_rating_list[src].append((pred_rating, true_rating))\n",
        "\n",
        "        recalls = dict()\n",
        "        precisions = dict()\n",
        "\n",
        "        for user_id, user_ratings in user_item_rating_list.items():\n",
        "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "            n_rel_and_rec_k = sum(\n",
        "                ((true_r >= threshold) and (est >= threshold))\n",
        "                for (est, true_r) in user_ratings[:k]\n",
        "            )\n",
        "\n",
        "            precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "            recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "        overall_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
        "        overall_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
        "\n",
        "        return overall_recall, overall_precision\n"
      ],
      "id": "m1ITH4xgCnfM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1470e6a7"
      },
      "outputs": [],
      "source": [
        "print(f\"BATCH_SIZE {BATCH_SIZE}\")"
      ],
      "id": "1470e6a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec3aee9d"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "# add decay to avoid overfit\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ],
      "id": "ec3aee9d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce5aa2f5"
      },
      "outputs": [],
      "source": [
        "r_mat_train_edge_index, r_mat_train_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(train_edge_index, train_edge_values)\n",
        "r_mat_val_edge_index, r_mat_val_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(val_edge_index, val_edge_values)\n",
        "r_mat_test_edge_index, r_mat_test_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(test_edge_index, test_edge_values)\n"
      ],
      "id": "ce5aa2f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53d7b752"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_recall_at_ks = []\n",
        "\n",
        "for iter in tqdm(range(ITERATIONS)):\n",
        "    # forward propagation\n",
        "\n",
        "    # the rating here is based on r_mat\n",
        "    pred_ratings = model.forward(train_edge_index, train_edge_values)\n",
        "\n",
        "\n",
        "    train_loss = loss_func(pred_ratings, r_mat_train_edge_values.view(-1,1))\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # going over validation set\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pred_ratings = model.forward(val_edge_index, val_edge_values)\n",
        "\n",
        "            val_loss = loss_func(val_pred_ratings, r_mat_val_edge_values.view(-1,1)).sum()\n",
        "\n",
        "            recall_at_k, precision_at_k = get_recall_at_k(r_mat_val_edge_index,\n",
        "                                                          r_mat_val_edge_values,\n",
        "                                                          val_pred_ratings,\n",
        "                                                          k = 20\n",
        "                                                         )\n",
        "\n",
        "\n",
        "            val_recall_at_ks.append(round(recall_at_k, 5))\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            print(f\"[Iteration {iter}/{ITERATIONS}], train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss.item(), 5)},  recall_at_k {round(recall_at_k, 5)}, precision_at_k {round(precision_at_k, 5)}\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "id": "53d7b752"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13B-tzVKDblT"
      },
      "outputs": [],
      "source": [
        "new_url = 'https://files.grouplens.org/datasets/movielens/ml-25m.zip'\n",
        "extract_zip(download_url(new_url, '.'), '.')\n",
        "\n",
        "new_movie_path = './ml-25m/movies.csv'\n",
        "new_rating_path = './ml-25m/ratings.csv'\n",
        "new_rating_df = pd.read_csv(new_rating_path)\n",
        "new_movie_df = pd.read_csv(new_movie_path)\n",
        "\n",
        "# Label encode user and movie IDs for the new dataset\n",
        "new_lbl_user = preprocessing.LabelEncoder()\n",
        "new_lbl_movie = preprocessing.LabelEncoder()\n",
        "new_rating_df.userId = new_lbl_user.fit_transform(new_rating_df.userId.values)\n",
        "new_rating_df.movieId = new_lbl_movie.fit_transform(new_rating_df.movieId.values)\n",
        "\n",
        "# Load edges between users and movies for the new dataset\n",
        "new_edge_index, new_edge_values = load_edge_csv(\n",
        "    new_rating_df,\n",
        "    src_index_col='userId',\n",
        "    dst_index_col='movieId',\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=1\n",
        ")\n",
        "\n",
        "# Convert to tensor\n",
        "new_edge_index = torch.LongTensor(new_edge_index)\n",
        "new_edge_values = torch.tensor(new_edge_values)"
      ],
      "id": "13B-tzVKDblT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdp8sJOB5rA9"
      },
      "outputs": [],
      "source": [
        "# define contants\n",
        "ITERATIONS = 5000\n",
        "EPOCHS = 10\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 10\n",
        "LAMBDA = 1e-6\n"
      ],
      "id": "Bdp8sJOB5rA9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmt_IKrN5r8S"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "# add decay to avoid overfit\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ],
      "id": "Gmt_IKrN5r8S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssQc_yEd5vv0"
      },
      "outputs": [],
      "source": [],
      "id": "ssQc_yEd5vv0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwJf9Fga53em"
      },
      "outputs": [],
      "source": [
        "r_mat_train_edge_index, r_mat_train_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(train_edge_index, train_edge_values)\n",
        "r_mat_val_edge_index, r_mat_val_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(val_edge_index, val_edge_values)\n",
        "r_mat_test_edge_index, r_mat_test_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(test_edge_index, test_edge_values)\n"
      ],
      "id": "CwJf9Fga53em"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3ekHlMz54tP"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_recall_at_ks = []\n",
        "\n",
        "for iter in tqdm(range(ITERATIONS)):\n",
        "    # forward propagation\n",
        "\n",
        "    # the rating here is based on r_mat\n",
        "    pred_ratings = model.forward(train_edge_index, train_edge_values)\n",
        "\n",
        "\n",
        "    train_loss = loss_func(pred_ratings, r_mat_train_edge_values.view(-1,1))\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # going over validation set\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pred_ratings = model.forward(val_edge_index, val_edge_values)\n",
        "\n",
        "            val_loss = loss_func(val_pred_ratings, r_mat_val_edge_values.view(-1,1)).sum()\n",
        "\n",
        "            recall_at_k, precision_at_k = get_recall_at_k(r_mat_val_edge_index,\n",
        "                                                          r_mat_val_edge_values,\n",
        "                                                          val_pred_ratings,\n",
        "                                                          k = 20\n",
        "                                                         )\n",
        "\n",
        "\n",
        "            val_recall_at_ks.append(round(recall_at_k, 5))\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            print(f\"[Iteration {iter}/{ITERATIONS}], train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss.item(), 5)},  recall_at_k {round(recall_at_k, 5)}, precision_at_k {round(precision_at_k, 5)}\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "id": "u3ekHlMz54tP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzJHVcB8ctca"
      },
      "outputs": [],
      "source": [
        "new_url = 'https://files.grouplens.org/datasets/movielens/tag-genome-2021'\n",
        "extract_zip(download_url(new_url, '.'), '.')\n",
        "\n",
        "new_movie_path = './tag-genome-2021/movies.csv'\n",
        "new_rating_path = './tag-genome-2021/ratings.csv'\n",
        "new_rating_df = pd.read_csv(new_rating_path)\n",
        "new_movie_df = pd.read_csv(new_movie_path)\n",
        "\n",
        "# Label encode user and movie IDs for the new dataset\n",
        "new_lbl_user = preprocessing.LabelEncoder()\n",
        "new_lbl_movie = preprocessing.LabelEncoder()\n",
        "new_rating_df.userId = new_lbl_user.fit_transform(new_rating_df.userId.values)\n",
        "new_rating_df.movieId = new_lbl_movie.fit_transform(new_rating_df.movieId.values)\n",
        "\n",
        "# Load edges between users and movies for the new dataset\n",
        "new_edge_index, new_edge_values = load_edge_csv(\n",
        "    new_rating_df,\n",
        "    src_index_col='userId',\n",
        "    dst_index_col='movieId',\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=1\n",
        ")\n",
        "\n",
        "# Convert to tensor\n",
        "new_edge_index = torch.LongTensor(new_edge_index)\n",
        "new_edge_values = torch.tensor(new_edge_values)"
      ],
      "id": "qzJHVcB8ctca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yWUVAmFfdMW"
      },
      "outputs": [],
      "source": [
        "# define contants\n",
        "ITERATIONS = 5000\n",
        "EPOCHS = 10\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 10\n",
        "LAMBDA = 1e-6\n"
      ],
      "id": "6yWUVAmFfdMW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usW_4i8bfiNx"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "# add decay to avoid overfit\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ],
      "id": "usW_4i8bfiNx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYY-3rszfqIB"
      },
      "outputs": [],
      "source": [
        "r_mat_train_edge_index, r_mat_train_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(train_edge_index, train_edge_values)\n",
        "r_mat_val_edge_index, r_mat_val_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(val_edge_index, val_edge_values)\n",
        "r_mat_test_edge_index, r_mat_test_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(test_edge_index, test_edge_values)\n"
      ],
      "id": "fYY-3rszfqIB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUWFsU06fzDo"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_recall_at_ks = []\n",
        "\n",
        "for iter in tqdm(range(ITERATIONS)):\n",
        "    # forward propagation\n",
        "\n",
        "    # the rating here is based on r_mat\n",
        "    pred_ratings = model.forward(train_edge_index, train_edge_values)\n",
        "\n",
        "\n",
        "    train_loss = loss_func(pred_ratings, r_mat_train_edge_values.view(-1,1))\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # going over validation set\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pred_ratings = model.forward(val_edge_index, val_edge_values)\n",
        "\n",
        "            val_loss = loss_func(val_pred_ratings, r_mat_val_edge_values.view(-1,1)).sum()\n",
        "\n",
        "            recall_at_k, precision_at_k = get_recall_at_k(r_mat_val_edge_index,\n",
        "                                                          r_mat_val_edge_values,\n",
        "                                                          val_pred_ratings,\n",
        "                                                          k = 20\n",
        "                                                         )\n",
        "\n",
        "\n",
        "            val_recall_at_ks.append(round(recall_at_k, 5))\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            print(f\"[Iteration {iter}/{ITERATIONS}], train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss.item(), 5)},  recall_at_k {round(recall_at_k, 5)}, precision_at_k {round(precision_at_k, 5)}\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "id": "gUWFsU06fzDo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTuKtQzW6gEO"
      },
      "outputs": [],
      "source": [
        "def get_recall_at_k(input_edge_index,\n",
        "                     input_edge_values, # the true label of actual ratings for each user/item interaction\n",
        "                     pred_ratings, # the list of predicted ratings\n",
        "                     k=10,\n",
        "                     threshold=3.5):\n",
        "    with torch.no_grad():\n",
        "        user_item_rating_list = defaultdict(list)\n",
        "\n",
        "        for i in range(len(input_edge_index[0])):\n",
        "            src = input_edge_index[0][i].item()\n",
        "            dest = input_edge_index[1][i].item()\n",
        "            true_rating = input_edge_values[i].item()\n",
        "            pred_rating = pred_ratings[i].item()\n",
        "\n",
        "            user_item_rating_list[src].append((pred_rating, true_rating))\n",
        "\n",
        "        recalls = dict()\n",
        "        precisions = dict()\n",
        "\n",
        "        for user_id, user_ratings in user_item_rating_list.items():\n",
        "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "            n_rel_and_rec_k = sum(\n",
        "                ((true_r >= threshold) and (est >= threshold))\n",
        "                for (est, true_r) in user_ratings[:k]\n",
        "            )\n",
        "\n",
        "            precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "            recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "        overall_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
        "        overall_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
        "\n",
        "        return overall_recall, overall_precision\n"
      ],
      "id": "tTuKtQzW6gEO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq6iDGpHdKZY"
      },
      "outputs": [],
      "source": [],
      "id": "xq6iDGpHdKZY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58187223"
      },
      "source": [
        "# Plot (RMSE)"
      ],
      "id": "58187223"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30685ec8"
      },
      "outputs": [],
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "30685ec8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efc3f2a9"
      },
      "outputs": [],
      "source": [
        "f2 = plt.figure()\n",
        "plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('recall_at_k')\n",
        "plt.title('recall_at_k curves')\n",
        "plt.show()"
      ],
      "id": "efc3f2a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cb9b880"
      },
      "source": [
        "# Evaluation (RMSE)"
      ],
      "id": "7cb9b880"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fbabdb0"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_ratings = model.forward(test_edge_index, test_edge_values)\n",
        "    recall_at_k, precision_at_k = get_recall_at_k(r_mat_test_edge_index,\n",
        "                                                  r_mat_test_edge_values,\n",
        "                                                  pred_ratings, 20)\n",
        "    print(f\"recall_at_k {round(recall_at_k, 5)}, precision_at_k {round(precision_at_k, 5)}\")\n"
      ],
      "id": "9fbabdb0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5eaf75a"
      },
      "outputs": [],
      "source": [
        "def recommend_movies(user_id, model, lbl_user, lbl_movie, rating_df, movie_df, num_recommendations=10):\n",
        "    # Convert user_id to label encoding\n",
        "    encoded_user_id = lbl_user.transform([user_id])[0]\n",
        "\n",
        "    # Create a tensor for the given user\n",
        "    user_tensor = torch.LongTensor([[encoded_user_id]])\n",
        "\n",
        "    # Generate movie predictions for the user\n",
        "    with torch.no_grad():\n",
        "        # Get the embedding for the user\n",
        "        user_embedding = model.users_emb(user_tensor)\n",
        "\n",
        "        # Get all movie embeddings\n",
        "        all_movie_embeddings = model.items_emb.weight\n",
        "\n",
        "        # Calculate the predicted ratings for all movies using the specific user embedding\n",
        "        predicted_ratings = (user_embedding @ all_movie_embeddings.t()).squeeze()\n",
        "\n",
        "        # Convert the predicted ratings to a NumPy array\n",
        "        predicted_ratings = predicted_ratings.cpu().numpy()\n",
        "\n",
        "    # Inverse transform movie IDs to original IDs\n",
        "    movie_ids = lbl_movie.inverse_transform(np.arange(len(predicted_ratings)))\n",
        "\n",
        "    # Create a DataFrame with movie IDs and predicted ratings\n",
        "    recommendations_df = pd.DataFrame({'movieId': movie_ids, 'predicted_rating': predicted_ratings})\n",
        "\n",
        "    # Merge with the original movie data to get movie titles\n",
        "    recommendations_df = pd.merge(recommendations_df, movie_df[['movieId', 'title']], on='movieId', how='left')\n",
        "\n",
        "    # Exclude movies already rated by the user\n",
        "    user_rated_movies = rating_df[rating_df['userId'] == user_id]['movieId']\n",
        "    recommendations_df = recommendations_df[~recommendations_df['movieId'].isin(user_rated_movies)]\n",
        "\n",
        "    # Sort by predicted rating in descending order\n",
        "    recommendations_df = recommendations_df.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "    # Display the top N recommendations\n",
        "    top_recommendations = recommendations_df.head(num_recommendations)\n",
        "\n",
        "    print(f\"Top {num_recommendations} Movie Recommendations for User {user_id}:\\n\")\n",
        "    for i, row in top_recommendations.iterrows():\n",
        "        print(f\"{i + 1}. {row['title']} (Predicted Rating: {row['predicted_rating']:.2f})\")\n",
        "\n",
        "# Example usage:\n",
        "user_id_to_recommend = 4  # Replace with the desired user ID\n",
        "recommend_movies(user_id_to_recommend, model, lbl_user, lbl_movie, rating_df, movie_df)\n",
        "\n"
      ],
      "id": "e5eaf75a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzNkOI2xQB9r"
      },
      "outputs": [],
      "source": [],
      "id": "zzNkOI2xQB9r"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}